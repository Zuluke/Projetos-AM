{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from time import time\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
    "\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import random\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import requests\n",
    "import io\n",
    "    \n",
    "# Downloading the csv file from your GitHub account\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Zuluke/Projetos-AM/main/Projeto_Chico/Dataset/mfeat-fac\" # Make sure the url is the raw version of the file on GitHub\n",
    "download = requests.get(url).content\n",
    "fac = pd.read_csv(io.StringIO(download.decode('utf-8')),sep=\"\\s+\",header=None)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Zuluke/Projetos-AM/main/Projeto_Chico/Dataset/mfeat-fou\" # Make sure the url is the raw version of the file on GitHub\n",
    "download = requests.get(url).content\n",
    "fou = pd.read_csv(io.StringIO(download.decode('utf-8')),sep=\"\\s+\",header=None)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Zuluke/Projetos-AM/main/Projeto_Chico/Dataset/mfeat-zer\" # Make sure the url is the raw version of the file on GitHub\n",
    "download = requests.get(url).content\n",
    "zer = pd.read_csv(io.StringIO(download.decode('utf-8')),sep=\"\\s+\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label creation\n",
    "\n",
    "fac[\"digit\"] = [i for i in range(10) for __ in range(200)]\n",
    "\n",
    "fou[\"digit\"] = [i for i in range(10) for __ in range(200)]\n",
    "\n",
    "zer[\"digit\"] = [i for i in range(10) for __ in range(200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MMoTE_bHoeJF"
   },
   "outputs": [],
   "source": [
    "                                              # A função recebe o cluster i, e os índices l,k que correspondem a dois vetores que representam duas instâncias.\n",
    "def kernel_gaussian(vector1,l,vector2,k):   # função que calcula o kernel gaussiano, equação (10) do artigo.\n",
    "  kernel = vector1[l] - vector2[k]\n",
    "  kernel = np.sum(np.multiply(s,np.multiply(kernel,kernel)))\n",
    "  kernel = math.exp(kernel*(-1/2))\n",
    "  return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5oGGaSvUot00"
   },
   "outputs": [],
   "source": [
    "def u_ki(k,i):                #calcula os graus de pertencimento u_ik\n",
    "  numerator = (2-(2*kernel_matrix[k]))\n",
    "  belong = sum([(numerator/(2-(2*kernel_gaussian(x,k,g,h))))**(1/(m-1)) for h in range(c)])\n",
    "  belong = belong ** -1\n",
    "  return belong\n",
    "\n",
    "def update_u():               #atualiza todos os valores de u na matriz\n",
    "  for k in range(n):\n",
    "    aux = 0\n",
    "    for z in range(c):\n",
    "      if(np.array_equal(x[k],g[z])):\n",
    "        u[k] = 0\n",
    "        u[k][z] = 1\n",
    "        aux += 1\n",
    "    if(aux==0):\n",
    "      for i in range(c):\n",
    "          u[k][i] = u_ki(k,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YVt4nbRko35-"
   },
   "outputs": [],
   "source": [
    "def update_J():\n",
    "  objective = np.sum(np.sum(np.multiply(u_m,(2-kernel_matrix*2)),axis=0))\n",
    "  return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qmmpT6UXo5dT"
   },
   "outputs": [],
   "source": [
    "def update_g():\n",
    "  multiplied_aux = np.multiply(u_m,kernel_matrix)\n",
    "  numerator = np.sum(np.multiply(multiplied_aux[:,np.newaxis],np.repeat(x[:,:, np.newaxis], c, axis=2)), axis = 0)\n",
    "  denominator = np.sum(multiplied_aux, axis = 0)\n",
    "  g = numerator/denominator\n",
    "  g = g.transpose()\n",
    "  return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FD6b1nnSo7V7"
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal, getcontext\n",
    "import time\n",
    "\n",
    "getcontext().prec = 120\n",
    "def update_s():\n",
    "  for i in range(c):\n",
    "    multiplied_aux = np.multiply(u_m[:,i],kernel_matrix[:,i])\n",
    "    for j in range(p):\n",
    "      numerator = Decimal('1')\n",
    "      expoent = Decimal(p)\n",
    "      expoent = numerator/expoent\n",
    "      for h in range(p):\n",
    "        top_aux = x[:,h] - g[i,h]\n",
    "        numerator_aux = np.multiply(multiplied_aux,np.multiply(top_aux,top_aux))\n",
    "        numerator_aux = np.sum(numerator_aux)\n",
    "        numerator_aux = Decimal(numerator_aux)\n",
    "        numerator = numerator * numerator_aux\n",
    "      numerator = numerator**expoent\n",
    "      numerator = float(numerator)\n",
    "      bot_aux = x[:,j] - g[i,j]\n",
    "      denominator = np.multiply(multiplied_aux,np.multiply(bot_aux,bot_aux))\n",
    "      denominator = np.sum(denominator)\n",
    "      s[i,j] = numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "whTbYI9Zo_2A"
   },
   "outputs": [],
   "source": [
    "def update_kernel():\n",
    "  kernel_m = np.multiply(np.repeat(s.transpose()[np.newaxis,:,:], n, axis=0),(np.subtract(x[:,:,np.newaxis],np.repeat(g.transpose()[np.newaxis,:,:], n, axis=0)))**2)\n",
    "  kernel_m = np.sum(kernel_m, axis=1) * (-1/2)\n",
    "  kernel_m = np.exp(kernel_m)\n",
    "  return kernel_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5HppTh3DpBis"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "classes = iris.target\n",
    "dataset = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGeBjikdpFeO",
    "outputId": "598c2c7c-c738-4b8d-f277-792b24724cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0; Função Objetivo J: 2.9358843629950337\n",
      "epoch: 1; Função Objetivo J: 1.895956131434533\n",
      "epoch: 2; Função Objetivo J: 1.2530120329151384\n",
      "epoch: 3; Função Objetivo J: 1.0200408862615649\n",
      "epoch: 4; Função Objetivo J: 0.9876864580897302\n",
      "epoch: 5; Função Objetivo J: 0.9767945038546225\n",
      "epoch: 6; Função Objetivo J: 0.972135589729852\n",
      "epoch: 7; Função Objetivo J: 0.9706935743298369\n",
      "epoch: 8; Função Objetivo J: 0.9706086847743953\n",
      "epoch: 9; Função Objetivo J: 0.9709589037172071\n",
      "Tempo de execução: 0.16960430145263672\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset = dataset\n",
    "\n",
    "min_val = np.min(dataset)                                       #normalizando valores\n",
    "max_val = np.max(dataset)\n",
    "scaled_data = (dataset - min_val) / (max_val - min_val)\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "\n",
    "n_clusters = 3                    #trocar pra 10 clusters quando for rodar na base do projeto\n",
    "n = dataset.shape[0]  #quantidade de instâncias n\n",
    "p = dataset.shape[1]  #quantidade de atributos p\n",
    "c = n_clusters       #quatidade de clusters c\n",
    "s = np.ones((1,p))    #inicialização da matriz que contém os parâmetros width s^2  / passo 7\n",
    "u = np.ones((n,c))\n",
    "u_m = np.ones((n,c))\n",
    "kernel_matrix = np.ones((n,c))                     #martiz de kernels\n",
    "x = scaled_data #dataset           #salva o dataset em x para concordar com a nomenclatura utilizada no artigo\n",
    "m = 1.6               # hiper-parâmetro do algoritmo\n",
    "epoch = 10\n",
    "e = 0.000001\n",
    "\n",
    "prototypes = random.sample(range(n), n_clusters)   # seleção randomizada dos índices dos protótipos dos clusters\n",
    "g = [x[i] for i in prototypes]  # colocando no vetor g de protótipos os vetores dos protótipos selecionados a partir dos índices    / passo 8\n",
    "g = np.array(g)\n",
    "\n",
    "start_time = time.time()\n",
    "kernel_matrix = update_kernel()\n",
    "update_u()                       #passo 10\n",
    "u_m = u**m\n",
    "J_NEW = update_J()               #passo 11\n",
    "\n",
    "for a in range(epoch):\n",
    "  kernel_matrix = update_kernel()\n",
    "  J_OLD = J_NEW                             #passo 13\n",
    "  update_s()                                 #passo 16\n",
    "  kernel_matrix = update_kernel()\n",
    "  g = update_g()                                 #passo 19\n",
    "  kernel_matrix = update_kernel()\n",
    "  update_u()                                 #passo 22\n",
    "  u_m = u**m\n",
    "  J_NEW = update_J()                         #passo 23\n",
    "  print(f'epoch: {a}; Função Objetivo J: {J_NEW}')\n",
    "  if(abs(J_NEW-J_OLD)<e):\n",
    "    break\n",
    "end_time = time.time()\n",
    "print(f'Tempo de execução: {end_time - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hULRZTCnpiCv",
    "outputId": "62780fd0-ddba-46db-a663-5b39d0ffac40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8340750470114582"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "pred = np.argmax(u, axis=1)\n",
    "adjusted_rand_score(pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PN5LrBRYpqVd",
    "outputId": "98f61987-f191-4cf8-8870-28b02c0ef12f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 53, 1: 50, 2: 47}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(pred, return_counts=True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Btga0TWqprwK",
    "outputId": "09ff2780-da91-4685-8b6e-211c8394afb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8307910368086072"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC = np.sum(u**2)/n                                   #modified partition coeficient\n",
    "MPC = 1 - (c/(c-1))*(1-PC)\n",
    "MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmnFhocYp1u1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
