{"cells":[{"cell_type":"markdown","metadata":{"id":"tOE-MxZkZw4Q"},"source":["# Atividade  \n","Ajustar o script para classificar gêneros musicais do Spotify considerando a base de dados [disponível no HuggingFace](https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset)."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"executionInfo":{"elapsed":2567,"status":"ok","timestamp":1712700558719,"user":{"displayName":"Eduardo Henrique X. de Melo e Menezes","userId":"07659237479936359934"},"user_tz":180},"id":"7vZeW8eirTs1","outputId":"8a788f78-6f11-4918-8e89-fea0e7d490fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 114000 entries, 0 to 113999\n","Data columns (total 21 columns):\n"," #   Column            Non-Null Count   Dtype  \n","---  ------            --------------   -----  \n"," 0   Unnamed: 0        114000 non-null  int64  \n"," 1   track_id          114000 non-null  object \n"," 2   artists           113999 non-null  object \n"," 3   album_name        113999 non-null  object \n"," 4   track_name        113999 non-null  object \n"," 5   popularity        114000 non-null  int64  \n"," 6   duration_ms       114000 non-null  int64  \n"," 7   explicit          114000 non-null  bool   \n"," 8   danceability      114000 non-null  float64\n"," 9   energy            114000 non-null  float64\n"," 10  key               114000 non-null  int64  \n"," 11  loudness          114000 non-null  float64\n"," 12  mode              114000 non-null  int64  \n"," 13  speechiness       114000 non-null  float64\n"," 14  acousticness      114000 non-null  float64\n"," 15  instrumentalness  114000 non-null  float64\n"," 16  liveness          114000 non-null  float64\n"," 17  valence           114000 non-null  float64\n"," 18  tempo             114000 non-null  float64\n"," 19  time_signature    114000 non-null  int64  \n"," 20  track_genre       114000 non-null  object \n","dtypes: bool(1), float64(9), int64(6), object(5)\n","memory usage: 17.5+ MB\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from tqdm import tqdm\n","\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","from sklearn import neighbors\n","from sklearn.model_selection import cross_validate,cross_val_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, classification_report\n","from math import sqrt\n","plt.rcParams['figure.figsize'] = [16, 10]\n","\n","pd.options.display.max_colwidth = 1000\n","pd.options.display.max_columns = 1000\n","pd.options.display.max_rows = 200\n","\n","import random\n","from random import seed\n","from random import randrange\n","import requests\n","import io\n","    \n","# Downloading the csv file from your GitHub account\n","\n","url = \"https://raw.githubusercontent.com/Zuluke/Projetos-AM/main/spotify_activity/dataset.csv\" # Make sure the url is the raw version of the file on GitHub\n","download = requests.get(url).content\n","\n","# Reading the downloaded content and turning it into a pandas dataframe\n","\n","df = pd.read_csv(io.StringIO(download.decode('utf-8')))\n","\n","df.info()"]},{"cell_type":"markdown","metadata":{"id":"WnIeZVdHczjc"},"source":["## Sem atributos categóricos"]},{"cell_type":"markdown","metadata":{"id":"1xyX7cxksql1"},"source":["### Preprocessamento  \n","Antes de tudo, é fundamental remover os atributos categóricos não-numéricos. No caso do atributo \"key\", ele será mantido sendo tratado com método one-hot encoding, tendo a coluna referente ao valor desconhecido descartada. Por último, os atributos popularity, duration_ms, loudness, tempo e time_signature serão padronizados com min_max_scaler para manter os valores entre 0 e 1."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2214,"status":"ok","timestamp":1712700560925,"user":{"displayName":"Eduardo Henrique X. de Melo e Menezes","userId":"07659237479936359934"},"user_tz":180},"id":"iG4x38QasoH_"},"outputs":[],"source":["scaler = MinMaxScaler()\n","\n","# Fazendo uma cópia de amostra do conjunto de dados\n","df_aj, _, = train_test_split(df, train_size=0.5, stratify=df.track_genre)\n","\n","# Removendo colunas categóricas nominais e de palavras de baixo calão\n","df_aj = df_aj.drop(columns=['Unnamed: 0','track_id','energy','speechiness','acousticness','instrumentalness','liveness',\n","                                      'duration_ms','explicit' ,'artists', 'popularity','loudness','time_signature',\n","                                      'album_name', 'tempo','track_name','key', 'mode','danceability'])\n","df_aj = df_aj\n","\n","df_aj.dropna(inplace=True, axis=0, how='any')\n","\n","# Criando dicionários para converter labels em números e vice-versa\n","dict_label_num = {}\n","dict_num_label = {}\n","for index in range(len(df_aj.track_genre.unique())):\n","  dict_label_num[df_aj.track_genre.unique()[index]] = index\n","  dict_num_label[index] = df_aj.track_genre.unique()[index]\n","\n","# Renomeando valores de track_genre\n","df_aj.track_genre = df_aj.track_genre.map(dict_label_num)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 56999 entries, 72592 to 106225\n","Data columns (total 16 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   artists           56999 non-null  object \n"," 1   album_name        56999 non-null  object \n"," 2   track_name        56999 non-null  object \n"," 3   popularity        56999 non-null  int64  \n"," 4   duration_ms       56999 non-null  int64  \n"," 5   explicit          56999 non-null  bool   \n"," 6   danceability      56999 non-null  float64\n"," 7   key               56999 non-null  int64  \n"," 8   loudness          56999 non-null  float64\n"," 9   mode              56999 non-null  int64  \n"," 10  instrumentalness  56999 non-null  float64\n"," 11  liveness          56999 non-null  float64\n"," 12  valence           56999 non-null  float64\n"," 13  tempo             56999 non-null  float64\n"," 14  time_signature    56999 non-null  int64  \n"," 15  track_genre       56999 non-null  int64  \n","dtypes: bool(1), float64(6), int64(6), object(3)\n","memory usage: 7.0+ MB\n"]}],"source":["df_aj.info()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":155,"status":"ok","timestamp":1712700560925,"user":{"displayName":"Eduardo Henrique X. de Melo e Menezes","userId":"07659237479936359934"},"user_tz":180},"id":"Rn_uTiAb_Cm-"},"outputs":[],"source":["# Divisão de dados de atributos e classe\n","sptf_X = df_aj.drop(columns='track_genre') #caracteristicas\n","sptf_Y = df_aj.track_genre #classe\n","\n","# Divisão em conjuntos de treino, teste e validação\n","sptf_X_train, sptf_X_test, sptf_Y_train, sptf_Y_test = train_test_split(sptf_X, sptf_Y, test_size=0.40, random_state=10)\n","sptf_X_test, sptf_X_valid, sptf_Y_test, sptf_Y_valid = train_test_split(sptf_X_test, sptf_Y_test, test_size=0.50, random_state=10)\n","\n","sptf_X_train = sptf_X_train.values\n","sptf_X_test = sptf_X_test.values\n","sptf_X_valid = sptf_X_valid.values\n","sptf_Y_train = sptf_Y_train.values\n","sptf_Y_test = sptf_Y_test.values\n","sptf_Y_valid = sptf_Y_valid.values"]},{"cell_type":"markdown","metadata":{"id":"7NpzgXTl-zXD"},"source":["### KNN"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":937},"executionInfo":{"elapsed":3589068,"status":"ok","timestamp":1712687986145,"user":{"displayName":"Eduardo Henrique X. de Melo e Menezes","userId":"07659237479936359934"},"user_tz":180},"id":"VpwFnpyE-2Lr","outputId":"df7a250a-df21-4c69-8235-6ccbc2eb4b85"},"outputs":[{"name":"stderr","output_type":"stream","text":["Distância euclidean:   0%|          | 0/40 [00:00<?, ?it/s]\n"]},{"ename":"ValueError","evalue":"\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n    return self._fit(X, y)\n           ^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 454, in _fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Teen Idols'\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n    return self._fit(X, y)\n           ^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 454, in _fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Mushroomhead'\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tqdm(k_range, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistância \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     15\u001b[0m   knn \u001b[38;5;241m=\u001b[39m neighbors\u001b[38;5;241m.\u001b[39mKNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mj, metric\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m---> 16\u001b[0m   scores \u001b[38;5;241m=\u001b[39m cross_val_score(knn, sptf_X_train, sptf_Y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m   k_scores_train\u001b[38;5;241m.\u001b[39mappend(scores\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m>\u001b[39m best_f1:\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n    return self._fit(X, y)\n           ^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 454, in _fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Teen Idols'\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n    return self._fit(X, y)\n           ^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 454, in _fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1106, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 879, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 185, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Mushroomhead'\n"]}],"source":["# we create an instance of Neighbours Classifier and fit the data.\n","sptf_clf = neighbors.KNeighborsClassifier()\n","\n","# Construindo o espaco de busca por configuracoes do classificador\n","k_range = range(1, 81, 2) #k\n","k_scores_train = []\n","k_scores_train_full = []\n","k_scores_valid = []\n","vet_distancias = ['euclidean', 'manhattan']\n","best_f1 = 0\n","#p_range = range(1, 198) #k\n","# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\n","for k in vet_distancias:\n","  for j in tqdm(k_range, desc=f'Distância {k}'):\n","    knn = neighbors.KNeighborsClassifier(n_neighbors=j, metric=k)\n","    scores = cross_val_score(knn, sptf_X_train, sptf_Y_train, cv=5, scoring='f1_weighted')\n","    k_scores_train.append(scores.mean())\n","    if scores.mean() > best_f1:\n","      sptf_clf = neighbors.KNeighborsClassifier(n_neighbors=j, metric=k)\n","      best_f1 = scores.mean()\n","    knn.fit(sptf_X_train, sptf_Y_train)\n","    k_scores_train_full.append(f1_score(sptf_Y_train, knn.predict(sptf_X_train), average='weighted'))\n","    k_scores_valid.append(f1_score(sptf_Y_valid, knn.predict(sptf_X_valid), average='weighted'))\n","\n","#treinando o classificador\n","sptf_clf = sptf_clf.fit(sptf_X_train, sptf_Y_train)\n","\n","# plot to see clearly\n","plt.plot(list(range(0,len(k_scores_train))), k_scores_train)\n","plt.plot(list(range(0,len(k_scores_train_full))), k_scores_train_full)\n","plt.plot(list(range(0,len(k_scores_valid))), k_scores_valid)\n","plt.legend(('Score medio Treino CV', 'Conj. Treino', 'Conj. Validacao'),\n","           loc='upper right', shadow=True)\n","plt.xlabel('Values of K for KNN')\n","plt.ylabel('Cross-Validated Accuracy')\n","plt.show()\n","\n","print(\"F1 de treinamento clf: %0.3f\" %  f1_score(sptf_Y_train, sptf_clf.predict(sptf_X_train), average='weighted'))\n","print(\"F1 de validação clf: %0.3f\" %  f1_score(sptf_Y_valid, sptf_clf.predict(sptf_X_valid), average='weighted'))\n","print(\"F1 de teste clf: %0.3f\" %  f1_score(sptf_Y_test, sptf_clf.predict(sptf_X_test), average='weighted'))"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1712688057396,"user":{"displayName":"Eduardo Henrique X. de Melo e Menezes","userId":"07659237479936359934"},"user_tz":180},"id":"PCypFP9LMq5N","outputId":"aaa65b46-bf32-4aa4-a4cf-021009dcb8b3"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=1)</pre></div></div></div></div></div>"],"text/plain":["KNeighborsClassifier(metric='euclidean', n_neighbors=1)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["sptf_clf"]},{"cell_type":"markdown","metadata":{"id":"KxxBEm6U-2ul"},"source":["### LVQ"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# LVQ for the Ionosphere Dataset\n","from random import seed\n","from random import randrange\n","from csv import reader\n","from math import sqrt\n","\n","# Load a CSV file\n","def load_csv(filename):\n","\tdataset = list()\n","\twith open(filename, 'r') as file:\n","\t\tcsv_reader = reader(file)\n","\t\tfor row in csv_reader:\n","\t\t\tif not row:\n","\t\t\t\tcontinue\n","\t\t\tdataset.append(row)\n","\treturn dataset\n","\n","# Convert string column to float\n","def str_column_to_float(dataset, column):\n","\tfor row in dataset:\n","\t\trow[column] = float(row[column].strip())\n","\n","# Convert string column to integer\n","def str_column_to_int(dataset, column):\n","\tclass_values = [row[column] for row in dataset]\n","\tunique = set(class_values)\n","\tlookup = dict()\n","\tfor i, value in enumerate(unique):\n","\t\tlookup[value] = i\n","\tfor row in dataset:\n","\t\trow[column] = lookup[row[column]]\n","\treturn lookup\n","\n","# Split a dataset into k folds\n","def cross_validation_split(dataset, n_folds):\n","\tdataset_split = list()\n","\tdataset_copy = list(dataset)\n","\tfold_size = int(len(dataset) / n_folds)\n","\tfor i in range(n_folds):\n","\t\tfold = list()\n","\t\twhile len(fold) < fold_size:\n","\t\t\tindex = randrange(len(dataset_copy))\n","\t\t\tfold.append(dataset_copy.pop(index))\n","\t\tdataset_split.append(fold)\n","\treturn dataset_split\n","\n","# Calculate accuracy percentage\n","def accuracy_metric(actual, predicted):\n","\tcorrect = 0\n","\tfor i in range(len(actual)):\n","\t\tif actual[i] == predicted[i]:\n","\t\t\tcorrect += 1\n","\treturn correct / float(len(actual)) * 100.0\n","\n","# Evaluate an algorithm using a cross validation split\n","def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n","\tfolds = cross_validation_split(dataset, n_folds)\n","\tscores = list()\n","\tfor fold in folds:\n","\t\ttrain_set = list(folds)\n","\t\ttrain_set.remove(fold)\n","\t\ttrain_set = sum(train_set, [])\n","\t\ttest_set = list()\n","\t\tfor row in fold:\n","\t\t\trow_copy = list(row)\n","\t\t\ttest_set.append(row_copy)\n","\t\t\trow_copy[-1] = None\n","\t\tpredicted = algorithm(train_set, test_set, *args)\n","\t\tactual = [row[-1] for row in fold]\n","\t\taccuracy = accuracy_metric(actual, predicted)\n","\t\tscores.append(accuracy)\n","\treturn scores\n","\n","# calculate the Euclidean distance between two vectors\n","def euclidean_distance(row1, row2):\n","\tdistance = 0.0\n","\tfor i in range(len(row1)-1):\n","\t\tdistance += (row1[i] - row2[i])**2\n","\treturn sqrt(distance)\n","\n","# Locate the best matching unit\n","def get_best_matching_unit(codebooks, test_row):\n","\tdistances = list()\n","\tfor codebook in codebooks:\n","\t\tdist = euclidean_distance(codebook, test_row)\n","\t\tdistances.append((codebook, dist))\n","\tdistances.sort(key=lambda tup: tup[1])\n","\treturn distances[0][0]\n","\n","# Make a prediction with codebook vectors\n","def predict(codebooks, test_row):\n","\tbmu = get_best_matching_unit(codebooks, test_row)\n","\treturn bmu[-1]\n","\n","# Create a random codebook vector\n","def random_codebook(train):\n","\tn_records = len(train)\n","\tn_features = len(train[0])\n","\tcodebook = [train[randrange(n_records)][i] for i in range(n_features)]\n","\treturn codebook\n","\n","# Train a set of codebook vectors\n","def train_codebooks(train, n_codebooks, lrate, epochs):\n","\tcodebooks = [random_codebook(train) for i in range(n_codebooks)]\n","\tfor epoch in range(epochs):\n","\t\trate = lrate * (1.0-(epoch/float(epochs)))\n","\t\tfor row in train:\n","\t\t\tbmu = get_best_matching_unit(codebooks, row)\n","\t\t\tfor i in range(len(row)-1):\n","\t\t\t\terror = row[i] - bmu[i]\n","\t\t\t\tif bmu[-1] == row[-1]:\n","\t\t\t\t\tbmu[i] += rate * error\n","\t\t\t\telse:\n","\t\t\t\t\tbmu[i] -= rate * error\n","\treturn codebooks\n","\n","# LVQ Algorithm\n","def learning_vector_quantization(train, test, n_codebooks, lrate, epochs):\n","\tcodebooks = train_codebooks(train, n_codebooks, lrate, epochs)\n","\tpredictions = list()\n","\tfor row in test:\n","\t\toutput = predict(codebooks, row)\n","\t\tpredictions.append(output)\n","\treturn(predictions)\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":236175,"status":"ok","timestamp":1712719373790,"user":{"displayName":"Eduardo Henrique X. de Melo e Menezes","userId":"07659237479936359934"},"user_tz":180},"id":"WuPYO6Sr-4Nk","outputId":"0ac5e337-b0e9-4919-a1b2-57a0d249109c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Taxa 0.01: 100%|██████████| 3/3 [08:23<00:00, 167.73s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Rate: 0.01\n","Melhores pontuações: [0.000129212694109098, 0.00014653959651258951, 0.00021208604076609303, 0.00014357673779124687, 0.00013486823025896043]\n","Melhor F1-score médio: 0.000% \n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["Taxa 0.2:   0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","Taxa 0.2:  33%|███▎      | 1/3 [03:51<07:43, 231.58s/it]C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","Taxa 0.2:  67%|██████▋   | 2/3 [07:34<03:46, 226.73s/it]C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar add\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:78: RuntimeWarning: overflow encountered in scalar power\n","  distance += (row1[i] - row2[i])**2\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:114: RuntimeWarning: overflow encountered in scalar subtract\n","  bmu[i] -= rate * error\n","C:\\Users\\pichau\\AppData\\Local\\Temp\\ipykernel_16572\\3645881548.py:112: RuntimeWarning: invalid value encountered in scalar add\n","  bmu[i] += rate * error\n","Taxa 0.2:  67%|██████▋   | 2/3 [09:43<04:51, 291.86s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rate \u001b[38;5;129;01min\u001b[39;00m learn_rate:\n\u001b[0;32m     34\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m prototypes \u001b[38;5;129;01min\u001b[39;00m tqdm(n_codebooks, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTaxa \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m \t\tscores \u001b[38;5;241m=\u001b[39m evaluate_algorithm(dataset, learning_vector_quantization, n_folds, prototypes, rate, n_epochs)\n\u001b[0;32m     36\u001b[0m \t\t\u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28msum\u001b[39m(scores)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scores))) \u001b[38;5;241m>\u001b[39m best_mean_f1:\n\u001b[0;32m     37\u001b[0m \t\t\tbest_mean_f1 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(scores)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mlen\u001b[39m(scores)))\n","Cell \u001b[1;32mIn[20], line 15\u001b[0m, in \u001b[0;36mevaluate_algorithm\u001b[1;34m(dataset, algorithm, n_folds, *args)\u001b[0m\n\u001b[0;32m     13\u001b[0m \ttest_set\u001b[38;5;241m.\u001b[39mappend(row_copy)\n\u001b[0;32m     14\u001b[0m \trow_copy[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m predicted \u001b[38;5;241m=\u001b[39m algorithm(train_set, test_set, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m     16\u001b[0m actual \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m folds[fold]]\n\u001b[0;32m     17\u001b[0m f1score \u001b[38;5;241m=\u001b[39m f1_score(actual, predicted, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[1;32mIn[19], line 119\u001b[0m, in \u001b[0;36mlearning_vector_quantization\u001b[1;34m(train, test, n_codebooks, lrate, epochs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearning_vector_quantization\u001b[39m(train, test, n_codebooks, lrate, epochs):\n\u001b[1;32m--> 119\u001b[0m \tcodebooks \u001b[38;5;241m=\u001b[39m train_codebooks(train, n_codebooks, lrate, epochs)\n\u001b[0;32m    120\u001b[0m \tpredictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m    121\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m test:\n","Cell \u001b[1;32mIn[19], line 108\u001b[0m, in \u001b[0;36mtrain_codebooks\u001b[1;34m(train, n_codebooks, lrate, epochs)\u001b[0m\n\u001b[0;32m    106\u001b[0m rate \u001b[38;5;241m=\u001b[39m lrate \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m-\u001b[39m(epoch\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(epochs)))\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m train:\n\u001b[1;32m--> 108\u001b[0m \tbmu \u001b[38;5;241m=\u001b[39m get_best_matching_unit(codebooks, row)\n\u001b[0;32m    109\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(row)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    110\u001b[0m \t\terror \u001b[38;5;241m=\u001b[39m row[i] \u001b[38;5;241m-\u001b[39m bmu[i]\n","Cell \u001b[1;32mIn[19], line 85\u001b[0m, in \u001b[0;36mget_best_matching_unit\u001b[1;34m(codebooks, test_row)\u001b[0m\n\u001b[0;32m     83\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m codebook \u001b[38;5;129;01min\u001b[39;00m codebooks:\n\u001b[1;32m---> 85\u001b[0m \tdist \u001b[38;5;241m=\u001b[39m euclidean_distance(codebook, test_row)\n\u001b[0;32m     86\u001b[0m \tdistances\u001b[38;5;241m.\u001b[39mappend((codebook, dist))\n\u001b[0;32m     87\u001b[0m distances\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m tup: tup[\u001b[38;5;241m1\u001b[39m])\n","Cell \u001b[1;32mIn[19], line 78\u001b[0m, in \u001b[0;36meuclidean_distance\u001b[1;34m(row1, row2)\u001b[0m\n\u001b[0;32m     76\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(row1)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 78\u001b[0m \tdistance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (row1[i] \u001b[38;5;241m-\u001b[39m row2[i])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sqrt(distance)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","\n","# Adjusting evaluation algorithm with cross validation split to consider F1-score\n","def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n","\tfolds = cross_validation_split(dataset, n_folds)\n","\tscores = list()\n","\tfor fold in range(len(folds)):\n","\t\ttrain_set = [folds[index] for index in range(len(folds)) if (not (index != fold))]\n","\t\ttrain_set = sum(train_set, [])\n","\t\ttest_set = list()\n","\t\tfor row in folds[fold]:\n","\t\t\trow_copy = list(row)\n","\t\t\ttest_set.append(row_copy)\n","\t\t\trow_copy[-1] = None\n","\t\tpredicted = algorithm(train_set, test_set, *args)\n","\t\tactual = [row[-1] for row in folds[fold]]\n","\t\tf1score = f1_score(actual, predicted, average='weighted')\n","\t\tscores.append(f1score)\n","\treturn scores\n","\n","# Test LVQ on Spotify dataset\n","random.seed(1)\n","# load and prepare data\n","dataset = df_aj.copy().values\n","# evaluate algorithm\n","n_folds = 5\n","n_epochs = 20\n","learn_rate = [0.01,0.2, 0.5]\n","n_codebooks = [40,50,60]\n","best_mean_f1 = [0]\n","best_scores = [0] * n_folds\n","\n","for rate in learn_rate:\n","\tfor prototypes in tqdm(n_codebooks, desc=f'Taxa {rate}'):\n","\t\tscores = evaluate_algorithm(dataset, learning_vector_quantization, n_folds, prototypes, rate, n_epochs)\n","\t\tif (sum(scores)/float(len(scores))) > best_mean_f1:\n","\t\t\tbest_mean_f1 = (sum(scores)/float(len(scores)))\n","\t\t\tbest_scores = scores\n","\t\n","\tprint(f'Rate: {rate}')\n","\tprint('Melhores pontuações: %s' % best_scores)\n","\tprint('Melhor F1-score médio: %.3f%%' % best_mean_f1,'\\n\\n')\n","\n","print('Melhores pontuações: %s' % best_scores)\n","print('Melhor F1-score médio: %.6f%%' % best_mean_f1)"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
